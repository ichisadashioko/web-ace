{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import math\n",
    "import requests\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common import keys\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "url = 'https://web-ace.jp/youngaceup/contents/1000117/episode/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://web-ace.jp'\n",
    "dl_root = 'web-ace'\n",
    "\n",
    "def get_chap_images(url):\n",
    "    \"\"\"\n",
    "    Sample url: https://web-ace.jp/youngaceup/contents/1000117/episode/3711/\n",
    "    \n",
    "    Turn off image loading to reduce load time (we will download directly from url later).\n",
    "    \"\"\"\n",
    "    driver.get(url)\n",
    "    # scroll to the end of the page to load all the images (they use JavaScript to save bandwidth)\n",
    "    body = driver.find_element_by_tag_name('body')\n",
    "#     body.send_keys(keys.Keys.END)\n",
    "    for _ in range(5):\n",
    "        body.send_keys(keys.Keys.END)\n",
    "        time.sleep(0.2)\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source)\n",
    "    img_list = soup.find('div', attrs={\n",
    "        'class': 'lazy-container'\n",
    "    }).find_all('img', attrs={\n",
    "        'class': 'viewerFixedImage'\n",
    "    })\n",
    "    img_urls = [base_url + img.attrs['src'] for img in img_list]\n",
    "    return img_urls\n",
    "\n",
    "def dl_image(url, basename, root):\n",
    "    if not os.path.exists(root):\n",
    "        os.makedirs(root)\n",
    "    ext = os.path.splitext(url)[1]\n",
    "    filename = basename + ext\n",
    "    filepath = f'{root}/{filename}'\n",
    "    if os.path.exists(filepath):\n",
    "        return\n",
    "    with open(filepath, 'wb') as handle:\n",
    "        res = requests.get(url, stream=True)\n",
    "        if not res.ok:\n",
    "            print(res)\n",
    "        for block in res.iter_content(1024):\n",
    "            if not block:\n",
    "                break\n",
    "            handle.write(block)\n",
    "\n",
    "def dl_manga(url):\n",
    "    \"\"\"\n",
    "    Sample url: https://web-ace.jp/youngaceup/contents/1000117/episode/\n",
    "    \"\"\"\n",
    "    driver.get(url)\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source)\n",
    "    # get the title\n",
    "    title = soup.find('h2', attrs={'class': 'clr-young-ace-up'}).text\n",
    "    # get the list of chapters\n",
    "    anchor_list = soup.find('ul', attrs={'class': 'table-view'}).find_all('a')\n",
    "    chap_dicts = [{\n",
    "        'title': a.find('p', attrs={'class': 'text-bold'}).text,\n",
    "        'url': base_url + a.attrs['href'],\n",
    "    } for a in anchor_list if a.find('p', attrs={'class': 'text-bold'}) is not None]\n",
    "    chap_dicts.reverse()\n",
    "\n",
    "    for chap_dict in tqdm(chap_dicts):\n",
    "        chap_url = chap_dict['url']\n",
    "        img_urls = get_chap_images(chap_url)\n",
    "        chap_dict['images'] = img_urls\n",
    "    print('Got all images. Starting to download.')\n",
    "    for chap_idx in tqdm(range(len(chap_dicts))):\n",
    "        chap_dict = chap_dicts[chap_idx]\n",
    "        chap_root = f'{dl_root}/{title}/{str(chap_idx).zfill(2)}'\n",
    "        img_urls = chap_dict['images']\n",
    "        # for img_idx in tqdm(range(len(img_urls))):\n",
    "        for img_idx in range(len(img_urls)):\n",
    "            img_url = img_urls[img_idx]\n",
    "            basename = str(img_idx).zfill(2)\n",
    "            dl_image(img_url, basename, chap_root)\n",
    "    return chap_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download manga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:28<00:00,  3.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got all images. Starting to download.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [01:51<00:00, 13.19s/it]\n"
     ]
    }
   ],
   "source": [
    "url = 'https://web-ace.jp/youngaceup/contents/1000118/episode/'\n",
    "chap_dicts = dl_manga(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [01:57<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got all images. Starting to download.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [06:12<00:00,  6.75s/it]\n"
     ]
    }
   ],
   "source": [
    "url = 'https://web-ace.jp/youngaceup/contents/1000118/episode/'\n",
    "chap_dicts = dl_manga(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://web-ace.jp/youngaceup/contents/1000091/episode/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [02:18<00:00,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got all images. Starting to download.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:06<00:00,  7.39it/s]\n"
     ]
    }
   ],
   "source": [
    "manga_list = [\n",
    "#     'https://web-ace.jp/youngaceup/contents/1000117/episode/', # 世界最高の暗殺者、異世界貴族に転生するを読む\n",
    "    'https://web-ace.jp/youngaceup/contents/1000091/episode/', # 勇者、辞めます\n",
    "#     'https://web-ace.jp/youngaceup/contents/1000118/episode/', # Fate/Grand Order -Epic of Remnant- 亜種特異点EX 深海電脳楽土 SE.RA.PHを読む\n",
    "#     'https://web-ace.jp/youngaceup/contents/1000064/episode/', # パシリな僕と恋する番長さんを読む\n",
    "]\n",
    "\n",
    "dl_hist = []\n",
    "for manga_url in manga_list:\n",
    "    print(f'Downloading {manga_url}')\n",
    "    dl_dict = dl_manga(manga_url)\n",
    "    dl_hist.append(dl_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
